---
title: "DSE 6311 Hyperparameter Tuning & Model Evaluation"
author: "James Keegan"
date: "2025-04-24"
output: html_document
---

# Code Copied from Steven Martinez

############## Loading Libraries Function ####################

```{R}
load_libraries <- function(packages) {
  # Check for missing packages
  missing_packages <- packages[!(packages %in% installed.packages()[, "Package"])]
  
  # install missing packages
  if(length(missing_packages) > 0) {
    install.packages(missing_packages)
  }
  
  # Load all packages
  lapply(packages, library, character.only = TRUE)
  
  cat("All packages are loaded succesfully.\n")
}

# Loading necessary libraries
load_libraries(c("tidyverse", "lubridate", "stats", "ggplot2", "corrplot", "stringr", "stringi", "class", "tidymodels", "modeldata", "themis", "vip", "baguette", "janitor", "rvest", "yardstick", "gsheet", "caret", "randomForest", "here", "tibble", "dplyr", "ISAR", "tidyr", "mgcv", "teamcolors", "baseballr", "Lahman", "remotes", "ggcorrplot", "broom", "readr", "glmnet", "xgboost", "Matrix", "Metrics", "reshape2", "DMwR2", "splitstackshape"))

# Load only the necessary functions from 'car'
library(car, exclude = "select")

# Turning off warning messages
options(warnings = 0)

```

# Loading Dataset

```{R}
# Loading dataset
df <- read_csv("C:\\Users\\student\\Documents\\GitHub\\team-beta\\final_data\\balanced_rf_data.csv")
df <- df %>% rename_with(make.names)
df$TeamSuccess <- as.factor(df$TeamSuccess)

head(df)

```

```{R}
# My job for this week
# rf data knn model
# cross-validation: stratfied k-fold

```

# Modeling

```{R}
set.seed(123)

# Stratified 10-fold CV
ctrl <- trainControl(
  method = "cv",         # cross-validation
  number = 10,           # 10 folds
  # sampling = SMOTE,
  savePredictions = "final"  # keep predictions for evaluation
)

```

```{R}
# KNN Model
knn_model <- train(
  TeamSuccess ~ ., 
  data = df,
  method = "knn",          # K-Nearest Neighbors
  trControl = ctrl,
  tuneLength = 10,         # tests 10 different k values
  metric = "Accuracy"      # or "Kappa"
)

```

```{R}
# Predictions
pred <- knn_model$pred$pred
actual <- knn_model$pred$obs

# Ensure factor levels match (just in case)
pred <- factor(pred, levels = levels(actual))

# Confusion matrix and stats
confusionMatrix(pred, actual)

```

# With Help from Joe

```{R}
# Load Data
rf_data <- read.csv("final_data/rf_data.csv", check.names = F, row.names = 1)

rf_data$Team.Success <- as.factor(rf_data$Team.Success)

train_index <- createDataPartition(rf_data$Team.Success, p = 0.89, list = F)

train_data <- rf_data[train_index,]
test_data <- rf_data[-train_index,]

```

```{R}
# Set the seed for reproducibility
set.seed(123)

# train_data$Team.Success <- as.factor(data$Team.Success)

# Create stratified train-test split
train_index <- createDataPartition(data$Team.Success, p = 0.78, list = FALSE)

# Split the data into training and test sets
train_data <- data[train_index, ]
test_data <- data[-train_index, ]

```

```{R}
## Rename levels in Team.Success so train() can read them
levels(train_data$Team.Success)[levels(train_data$Team.Success) == "1"] <- "missed_po"
levels(train_data$Team.Success)[levels(train_data$Team.Success) == "2"] <- "made_po"
levels(train_data$Team.Success)[levels(train_data$Team.Success) == "3"] <- "runner_up"
levels(train_data$Team.Success)[levels(train_data$Team.Success) == "4"] <- "ws_winner"
levels(train_data$Team.Success)
```

```{R}
# Define trainControl with SMOTE
ctrl <- trainControl(
  method = "cv",           # k-fold cross-validation
  number = 10,              # 10 folds
  sampling = "smote", # apply SMOTE inside each fold
  classProbs = TRUE,
  savePredictions = "final"
)

```

```{R}
# Train KNN model
set.seed(500)
knn_model <- train(
  Team.Success ~ ., 
  data = train_data,
  method = "knn",
  trControl = ctrl,
  preProcess = c("center", "scale"),  # scale predictors before KNN
  tuneLength = 10                     # search over 10 different K values
)

```


```{r}
print(knn_model)
```



```{R}
## Rename levels in Team.Success so they match training data
levels(test_data$Team.Success)[levels(test_data$Team.Success) == "1"] <- "missed_po"
levels(test_data$Team.Success)[levels(test_data$Team.Success) == "2"] <- "made_po"
levels(test_data$Team.Success)[levels(test_data$Team.Success) == "3"] <- "runner_up"
levels(test_data$Team.Success)[levels(test_data$Team.Success) == "4"] <- "ws_winner"
levels(test_data$Team.Success)

```

```{R}
# Scale numeric data of test set
test_x <- test_data %>% dplyr::select(-Team.Success)
test_x <- as.data.frame(scale(test_x))
test_y <- test_data$Team.Success

test_data <- test_x %>% mutate(Team.Success = test_y)

```

```{R}
# Predict test set response with trained cross-validated kNN
predictions <- predict(knn_model_new, newdata = test_data)

# Create detailed confusion matrix
confusionMatrix(predictions, test_data$Team.Success)

```

```{R}
# Creating a heatmap table for the confusion matrix
conf_matrix <- table(Predicted = predictions, Actual = test_data$Team.Success) # Create the table as a matrix
conf_df <- as.data.frame(conf_matrix) # Convert to data frame for ggplot

# Plot heatmap
ggplot(conf_df, aes(x = Actual, y = Predicted, fill = Freq)) +
  geom_tile(color = "white") +
  geom_text(aes(label = Freq), size = 5, fontface = "bold") +
  scale_fill_gradient(low = "#deebf7", high = "#3182bd") +
  labs(title = "10-fold cross-validated kNN with LDA",
       subtitle = "Multiclass Team Success Response",
       x = "Team Success",
       y = "Predicted",
       fill = "Count") +
  theme_minimal(base_size = 14)

```

# Binary

```{R}
binary_ts = read.csv("C:\\Users\\student\\Documents\\DSE 6311\\Module 5\\Team Success Variable Data Playoffs or No Playoffs - Sheet1.csv")

original_data <- read.csv("C:\\Users\\student\\Documents\\GitHub\\team-beta\\images\\rf_data.csv")

data_remove_ts = original_data %>%
  select(-Team.Success) %>%
  rename(Tm = X)

data_remove_ts <- separate(data_remove_ts, col = Tm, into = c("Tm", "Year"), sep = "_")
data_remove_ts$Year = as.numeric(data_remove_ts$Year)

binary_data = data_remove_ts %>%
  left_join(binary_ts, by = c("Tm", "Year"))

binary_data = binary_data %>%
  select(-Tm, -Year)
head(binary_data)

```

```{R}
# Set the seed for reproducibility
set.seed(123)

binary_data$Team.Success <- as.factor(binary_data$Team.Success)

# Create stratified train-test split
train_index_binary <- createDataPartition(binary_data$Team.Success, p = 0.78, list = FALSE)

# Split the data into training and test sets
train_data_binary <- binary_data[train_index_binary, ]
test_data_binary <- binary_data[-train_index_binary, ]

```

```{R}
## Rename levels in Team.Success so train() can read them
levels(train_data_binary$Team.Success)[levels(train_data_binary$Team.Success) == "0"] <- "missed_po"
levels(train_data_binary$Team.Success)[levels(train_data_binary$Team.Success) == "1"] <- "made_po"
levels(train_data_binary$Team.Success)

```

```{R}
# Define trainControl with SMOTE
ctrl_binary <- trainControl(
  method = "cv",           # k-fold cross-validation
  number = 10,              # 10 folds
  sampling = "smote", # apply SMOTE inside each fold
  classProbs = TRUE,
  savePredictions = "final"
)

```

```{R}
# Train KNN model
set.seed(500)
knn_model_binary <- train(
  Team.Success ~ ., 
  data = train_data_binary,
  method = "knn",
  trControl = ctrl_binary,
  preProcess = c("center", "scale"),  # scale predictors before KNN
  tuneLength = 10                     # search over 10 different K values
)

```

```{R}
## Rename levels in Team.Success so they match training data
levels(test_data_binary$Team.Success)[levels(test_data_binary$Team.Success) == "0"] <- "missed_po"
levels(test_data_binary$Team.Success)[levels(test_data_binary$Team.Success) == "1"] <- "made_po"
levels(test_data_binary$Team.Success)

```

```{R}
# Scale numeric data of test set
test_x_binary <- test_data_binary %>% dplyr::select(-Team.Success)
test_x_binary <- as.data.frame(scale(test_x_binary))
test_y_binary <- test_data_binary$Team.Success

test_data_binary <- test_x_binary %>% mutate(Team.Success = test_y_binary)

```

```{R}
# Predict test set response with trained cross-validated kNN
predictions_binary <- predict(knn_model_binary, newdata = test_data_binary)

# Create detailed confusion matrix
confusionMatrix(predictions_binary, test_data_binary$Team.Success)

```

```{R}
# Creating a heatmap table for the confusion matrix
conf_matrix_binary <- table(Predicted = predictions_binary, Actual = test_data_binary$Team.Success) # Create the table as a matrix
conf_df_binary <- as.data.frame(conf_matrix_binary) # Convert to data frame for ggplot

# Plot heatmap
ggplot(conf_df_binary, aes(x = Actual, y = Predicted, fill = Freq)) +
  geom_tile(color = "white") +
  geom_text(aes(label = Freq), size = 5, fontface = "bold") +
  scale_fill_gradient(low = "#deebf7", high = "#3182bd") +
  labs(title = "10-fold cross-validated kNN with LDA",
       subtitle = "Multiclass Team Success Response",
       x = "Team Success",
       y = "Predicted",
       fill = "Count") +
  theme_minimal(base_size = 14)

```
